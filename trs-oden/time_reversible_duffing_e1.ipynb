{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c286a597-8183-4e39-94a9-ef7c45bc6b98",
   "metadata": {},
   "source": [
    "Reproducing code from https://github.com/inhuh/trs-oden/blob/main/run_exp1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbc6d992-20f0-4609-be29-331f3bab56ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Lambda, Layer\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Add, Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c923e822-19bc-4733-9d23-e2a3c276884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gradient(Layer):\n",
    "    def call(self, inputs, **kwargs):\n",
    "        x, y = inputs\n",
    "        return K.gradients(loss=y, variables=x)[0]\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0]\n",
    "\n",
    "\n",
    "def time_difference(x):\n",
    "    return x[:, 1:] - x[:, :-1]\n",
    "\n",
    "\n",
    "def reversing_operator(x, dim, with_batch):\n",
    "    if with_batch:\n",
    "        q = x[:, :, :dim]\n",
    "        p = -x[:, :, dim:]\n",
    "        return K.concatenate(tensors=[q, p], axis=-1)\n",
    "    else:\n",
    "        q = x[:, :dim]\n",
    "        p = -x[:, dim:]\n",
    "        return K.concatenate(tensors=[q, p], axis=-1)\n",
    "\n",
    "\n",
    "class ODENetwork:\n",
    "    def __init__(self, nb_object=1, nb_coords=1, function_type='ode', time_horizon=10, time_augment=False,\n",
    "                 nb_units=1000, nb_layers=1, activation='tanh',\n",
    "                 lambda_trs=0.0, use_time_dep_lambda=False, learning_rate=2e-4):\n",
    "        self.dim = int(nb_object * nb_coords)\n",
    "        self.T = time_horizon\n",
    "        self.augment = time_augment\n",
    "        self.units, self.layers = nb_units, nb_layers\n",
    "        self.act = activation\n",
    "        self.lambda_trs = lambda_trs\n",
    "        self.t_dep = use_time_dep_lambda\n",
    "        self.lr = learning_rate\n",
    "        if function_type == 'ode':\n",
    "            self.func = self.ode_function()\n",
    "        elif function_type == 'hamiltonian':\n",
    "            self.func = self.hamilton_equation()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "    def ode_function(self):\n",
    "        x = Input(shape=(int(2 * self.dim),))\n",
    "        if self.augment:\n",
    "            t = Input(shape=(1,))\n",
    "            h = Dense(units=self.units, activation=self.act)(Concatenate(axis=-1)([x, t]))\n",
    "        else:\n",
    "            h = Dense(units=self.units, activation=self.act)(x)\n",
    "        for _ in range((self.layers - 1)):\n",
    "            h = Dense(units=self.units, activation=self.act)(h)\n",
    "        y = Dense(units=int(2 * self.dim), use_bias=False)(h)\n",
    "        if self.augment:\n",
    "            return Model(inputs=[t, x], outputs=y)\n",
    "        else:\n",
    "            return Model(inputs=x, outputs=y)\n",
    "\n",
    "    def hamilton_equation(self):\n",
    "        x = Input(shape=(int(2 * self.dim),))\n",
    "        q, p = Lambda(lambda f: f[:, :self.dim])(x), Lambda(lambda f: f[:, self.dim:])(x)\n",
    "        if self.augment:\n",
    "            t = Input(shape=(1,))\n",
    "            v = Dense(units=self.units, activation=self.act)(Concatenate(axis=-1)([q, t]))\n",
    "            k = Dense(units=self.units, activation=self.act)(Concatenate(axis=-1)([p, t]))\n",
    "        else:\n",
    "            v = Dense(units=self.units, activation=self.act)(q)\n",
    "            k = Dense(units=self.units, activation=self.act)(p)\n",
    "        for _ in range((self.layers - 1)):\n",
    "            v = Dense(units=self.units, activation=self.act)(v)\n",
    "            k = Dense(units=self.units, activation=self.act)(k)\n",
    "        v = Dense(units=1, use_bias=False)(v)\n",
    "        k = Dense(units=1, use_bias=False)(k)\n",
    "        dq = Gradient()([p, k])\n",
    "        dp = Lambda(lambda f: -1 * f)(Gradient()([q, v]))\n",
    "        if self.augment:\n",
    "            return Model(inputs=[t, x], outputs=Concatenate(axis=-1)([dq, dp]))\n",
    "        else:\n",
    "            return Model(inputs=x, outputs=Concatenate(axis=-1)([dq, dp]))\n",
    "\n",
    "    def solver(self):\n",
    "        def l_ode(y_true, y_pred):\n",
    "            return K.mean(K.square(y_true - y_pred))\n",
    "\n",
    "        def l_trs(y_true, y_pred):\n",
    "            if self.t_dep:\n",
    "                norm_ts = ts / K.max(ts)\n",
    "                return K.mean(norm_ts[:, 1:, 0] * K.mean(K.square(reversing_operator(x=X, dim=self.dim, with_batch=True) - Xr), axis=-1))\n",
    "            else:\n",
    "                return K.mean(K.square(reversing_operator(x=X, dim=self.dim, with_batch=True) - Xr))\n",
    "\n",
    "        def l_trsoden(y_true, y_pred):\n",
    "            return l_ode(y_true, y_pred) + self.lambda_trs * l_trs(y_true, y_pred)\n",
    "\n",
    "        ts = Input(shape=(self.T + 1, 1))\n",
    "        dts = Lambda(function=time_difference)(ts)\n",
    "\n",
    "        x0 = Input(shape=(int(2 * self.dim),))\n",
    "        x = x0\n",
    "        xr = Lambda(function=reversing_operator, arguments={'dim': self.dim, 'with_batch': False})(x)\n",
    "\n",
    "        ls_x, ls_xr = [], []\n",
    "\n",
    "        for i in range(self.T):\n",
    "            t = Lambda(lambda f: f[:, i, :])(ts)\n",
    "            tr = Lambda(lambda f: -f)(t)\n",
    "            dt = Lambda(lambda f: f[:, i, :])(dts)\n",
    "\n",
    "            if self.augment:  # For time-augmented (non-autonomous) cases, we used Runge-Kutta 4th solver.\n",
    "                # Forward time evolution\n",
    "                dx1 = Lambda(lambda f: f*dt)(self.func([t, x]))\n",
    "                dx2 = Lambda(lambda f: f*dt)(self.func([Add()([t, Lambda(lambda f: 0.5*f)(dt)]), Add()([x, Lambda(lambda f: 0.5*f)(dx1)])]))\n",
    "                dx3 = Lambda(lambda f: f*dt)(self.func([Add()([t, Lambda(lambda f: 0.5*f)(dt)]), Add()([x, Lambda(lambda f: 0.5*f)(dx2)])]))\n",
    "                dx4 = Lambda(lambda f: f*dt)(self.func([Add()([t, dt]), Add()([x, dx3])]))\n",
    "                dx = Lambda(lambda f: (1/6)*f)(Add()([dx1, Lambda(lambda f: 2*f)(dx2), Lambda(lambda f: 2*f)(dx3), dx4]))\n",
    "                x = Add()([x, dx])\n",
    "                ls_x.append(x)\n",
    "\n",
    "                # Backward time evolution\n",
    "                dxr1 = Lambda(lambda f: -f*dt)(self.func([tr, xr]))\n",
    "                dxr2 = Lambda(lambda f: -f*dt)(self.func([Add()([tr, Lambda(lambda f: -0.5*f)(dt)]), Add()([xr, Lambda(lambda f: 0.5*f)(dxr1)])]))\n",
    "                dxr3 = Lambda(lambda f: -f*dt)(self.func([Add()([tr, Lambda(lambda f: -0.5*f)(dt)]), Add()([xr, Lambda(lambda f: 0.5*f)(dxr2)])]))\n",
    "                dxr4 = Lambda(lambda f: -f*dt)(self.func([Add()([tr, Lambda(lambda f: -f)(dt)]), Add()([xr, dxr3])]))\n",
    "                dxr = Lambda(lambda f: (1/6)*f)(Add()([dxr1, Lambda(lambda f: 2*f)(dxr2), Lambda(lambda f: 2*f)(dxr3), dxr4]))\n",
    "                xr = Add()([xr, dxr])\n",
    "                ls_xr.append(xr)\n",
    "\n",
    "            else:  # Leapfrog solver for autonomous systems\n",
    "                # Forward time evolution\n",
    "                q, p = Lambda(lambda f: f[:, :self.dim])(x), Lambda(lambda f: f[:, self.dim:])(x)\n",
    "                p = Add()([p, Lambda(lambda f: (0.5*f*dt)[:, self.dim:])(self.func(x))])\n",
    "                q = Add()([q, Lambda(lambda f: (1.0*f*dt)[:, :self.dim])(self.func(Concatenate(axis=-1)([q, p])))])\n",
    "                p = Add()([p, Lambda(lambda f: (0.5*f*dt)[:, self.dim:])(self.func(Concatenate(axis=-1)([q, p])))])\n",
    "                x = Concatenate(axis=-1)([q, p])\n",
    "                ls_x.append(x)\n",
    "\n",
    "                # Backward time evolution\n",
    "                qr, pr = Lambda(lambda f: f[:, :self.dim])(xr), Lambda(lambda f: f[:, self.dim:])(xr)\n",
    "                pr = Add()([pr, Lambda(lambda f: (-0.5*f*dt)[:, self.dim:])(self.func(xr))])\n",
    "                qr = Add()([qr, Lambda(lambda f: (-1.0*f*dt)[:, :self.dim])(self.func(Concatenate(axis=-1)([qr, pr])))])\n",
    "                pr = Add()([pr, Lambda(lambda f: (-0.5*f*dt)[:, self.dim:])(self.func(Concatenate(axis=-1)([qr, pr])))])\n",
    "                xr = Concatenate(axis=-1)([qr, pr])\n",
    "                ls_xr.append(xr)\n",
    "\n",
    "        X = Lambda(lambda f: K.stack(f, axis=1))(ls_x)\n",
    "        Xr = Lambda(lambda f: K.stack(f, axis=1))(ls_xr)\n",
    "\n",
    "        model = Model(inputs=[ts, x0], outputs=X)\n",
    "        model.compile(optimizer=Adam(lr=self.lr), loss=l_trsoden, metrics=[l_ode, l_trs])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca7eaad9-a380-4045-b00c-f3c4ae24048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_duffing import get_dataset\n",
    "from utils import leapfrog_solver, runge_kutta_solver, reshape_data\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "325f7351-ac36-41bf-a846-71d51312aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6017533d-d085-4d43-9091-f21e49dffe54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ajivani/generative_experiments/trs-oden'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this_dir = os.path.abspath(os.getcwd())\n",
    "this_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c503565-c6ab-4402-a0f4-ba1b6cf9b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309ffd44-42ca-4c37-90d8-b47a67e24d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description=None)\n",
    "    parser.add_argument('--save_folder', default='experiment-duffing-1', type=str)\n",
    "\n",
    "    # Data variables\n",
    "    parser.add_argument('--osc_params', default=(1, 0, 0, 0), type=tuple)\n",
    "    parser.add_argument('--train_nb_sample', default=50, type=int)\n",
    "    parser.add_argument('--train_nb_timestep', default=30, type=int)\n",
    "    parser.add_argument('--train_t_span', default=(0, 3), type=tuple)\n",
    "    parser.add_argument('--train_seed', default=0, type=int)\n",
    "    parser.add_argument('--train_noise_level', default=0.1, type=float)\n",
    "    parser.add_argument('--test_nb_sample', default=50, type=int)\n",
    "    parser.add_argument('--test_nb_timestep', default=200, type=int)\n",
    "    parser.add_argument('--test_t_span', default=(0, 20), type=tuple)\n",
    "    parser.add_argument('--test_seed', default=999, type=int)\n",
    "    parser.add_argument('--test_noise_level', default=0.0, type=float)\n",
    "\n",
    "    # Model variables\n",
    "    parser.add_argument('--nb_object', default=1, type=int)\n",
    "    parser.add_argument('--nb_coords', default=1, type=int)\n",
    "    parser.add_argument('--time_horizon', default=10, type=int)\n",
    "    parser.add_argument('--time_augment', action='store_true')\n",
    "    parser.add_argument('--nb_units', default=1000, type=int)\n",
    "    parser.add_argument('--nb_layers', default=1, type=int)\n",
    "    parser.add_argument('--activation', default='tanh', type=str)\n",
    "    parser.add_argument('--use_time_dep_lambda', action='store_true')\n",
    "    parser.add_argument('--ls_cond', default=[['ode', 0.0], ['hamiltonian', 0.0], ['ode', 10.0]])\n",
    "    parser.add_argument('--ls_color', default=['red', 'dodgerblue', 'seagreen'])\n",
    "    parser.add_argument('--learning_rate', default=2e-4, type=float)\n",
    "    parser.add_argument('--epochs', default=5000, type=int)\n",
    "    parser.add_argument('--verbose', default=0, type=int)\n",
    "\n",
    "    return parser.parse_args(args=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1381e19d-fd87-4153-828d-76d35b2d3868",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3079566b-b383-4c6a-8280-2a71f1796159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiment-duffing-1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b25660f-5fd4-4e88-ba04-e67fb36ee7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(args):\n",
    "    plt.rc('font', size=10)\n",
    "    plt.rc('axes', labelsize=12)\n",
    "    plt.rcParams['lines.linewidth'] = 3\n",
    "    plt.rcParams['figure.figsize'] = 4.5, 4\n",
    "\n",
    "    save_dir = os.path.join(this_dir, args.save_folder)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    print('save directory:', save_dir)\n",
    "\n",
    "    for i in range(len(args.ls_cond)):\n",
    "        cond, col = args.ls_cond[i], args.ls_color[i]\n",
    "        function_type, lambda_trs = cond[0], cond[1]\n",
    "        split_name = str(function_type) + '_' + str(lambda_trs) + '_' + str(args.use_time_dep_lambda)\n",
    "        print('experimental condition:', split_name)\n",
    "\n",
    "        ts, xs = get_dataset(nb_samples=args.train_nb_sample, nb_timestep=args.train_nb_timestep,\n",
    "                             t_span=args.train_t_span, seed=args.train_seed, noise_level=args.train_noise_level,\n",
    "                             params=args.osc_params)\n",
    "        t_train, x_train, y_train = reshape_data(ts=ts, xs=xs, substep=args.time_horizon)\n",
    "\n",
    "        oden = ODENetwork(nb_object=args.nb_object, nb_coords=args.nb_coords, function_type=function_type,\n",
    "                          time_horizon=args.time_horizon, time_augment=args.time_augment,\n",
    "                          nb_units=args.nb_units, nb_layers=args.nb_layers,\n",
    "                          activation=args.activation, lambda_trs=lambda_trs,\n",
    "                          use_time_dep_lambda=args.use_time_dep_lambda, learning_rate=args.learning_rate)\n",
    "\n",
    "        oden.solver().fit(x=[t_train, x_train], y=y_train, epochs=args.epochs, batch_size=len(x_train), verbose=args.verbose)\n",
    "        oden.func.save_weights(os.path.join(save_dir, split_name + '_' + 'weight.h5'))\n",
    "\n",
    "        ts, xs = get_dataset(nb_samples=args.test_nb_sample, nb_timestep=args.test_nb_timestep,\n",
    "                             t_span=args.test_t_span, seed=args.test_seed, noise_level=args.test_noise_level,\n",
    "                             params=args.osc_params)\n",
    "        t_test, x_test, y_test = ts, xs[:, 0, :], xs[:, 1:, :]\n",
    "\n",
    "        if args.time_augment:\n",
    "            y_pred = runge_kutta_solver(ts=t_test, x0=x_test, func=oden.func)\n",
    "        else:\n",
    "            y_pred = leapfrog_solver(ts=t_test, x0=x_test, func=oden.func, dim=int(args.nb_object * args.nb_coords))\n",
    "\n",
    "        q_true, p_true, q_pred, p_pred = y_test[:, :, 0], y_test[:, :, 1], y_pred[:, :, 0], y_pred[:, :, 1]\n",
    "        e_true = args.osc_params[0] * np.square(q_true) + (args.osc_params[1] * np.square(np.square(q_true)) / 2) + np.square(p_true)\n",
    "        e_pred = args.osc_params[0] * np.square(q_pred) + (args.osc_params[1] * np.square(np.square(q_pred)) / 2) + np.square(p_pred)\n",
    "\n",
    "        mse_t_per_sample = np.mean(np.mean(np.square(y_test - y_pred), axis=-1), axis=-1)\n",
    "        mse_t, std_t = 1e2 * np.mean(mse_t_per_sample), 1e2 * np.std(mse_t_per_sample)\n",
    "\n",
    "        mse_e_per_sample = np.mean(np.square(e_true - e_pred), axis=-1)\n",
    "        mse_e, std_e = 1e2 * np.mean(mse_e_per_sample), 1e2 * np.std(mse_e_per_sample)\n",
    "        print('trajectory MSE: {:.2f} pm {:.2f}'.format(mse_t, std_t))\n",
    "        print('energy MSE: {:.2f} pm {:.2f}'.format(mse_e, std_e))\n",
    "\n",
    "        result = {'ground_truth': y_test, 'predicted': y_pred, 'mse_t': mse_t, 'std_t': std_t, 'mse_e': mse_e, std_t: std_e}\n",
    "\n",
    "        with open(os.path.join(save_dir, split_name + '_' + 'result.pkl'), 'wb') as f:\n",
    "            pkl.dump(result, f)\n",
    "\n",
    "        plt.plot(q_true[1], p_true[1], c='k', label='Ground truth')\n",
    "        plt.plot(q_pred[1], p_pred[1], c=col, label=split_name)\n",
    "        plt.grid(), plt.legend()\n",
    "        plt.xlabel('Position q'), plt.ylabel('Momentum p')\n",
    "        plt.xlim([-1.2, 1.2]), plt.ylim([-1.2, 1.2])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, split_name + '_' + 'trajectory.png'))\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(t_test[0, 1:].squeeze(), e_true[1], c='k', label='Ground truth')\n",
    "        plt.plot(t_test[0, 1:].squeeze(), e_pred[1], c=col, label=split_name)\n",
    "        plt.grid(), plt.legend()\n",
    "        plt.xlabel('Time'), plt.ylabel('Total energy')\n",
    "        plt.xlim([0, args.test_t_span[1]]), plt.ylim([0, 1.2])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, split_name + '_' + 'energy.png'))\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ec5a612-2379-4af0-a368-69a355d9dd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save directory: /home/ajivani/generative_experiments/trs-oden/experiment-duffing-1\n",
      "experimental condition: ode_0.0_False\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 2), dtype=float32, sparse=None, name=keras_tensor_7>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 28\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     20\u001b[0m t_train, x_train, y_train \u001b[38;5;241m=\u001b[39m reshape_data(ts\u001b[38;5;241m=\u001b[39mts, xs\u001b[38;5;241m=\u001b[39mxs, substep\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtime_horizon)\n\u001b[1;32m     22\u001b[0m oden \u001b[38;5;241m=\u001b[39m ODENetwork(nb_object\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnb_object, nb_coords\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnb_coords, function_type\u001b[38;5;241m=\u001b[39mfunction_type,\n\u001b[1;32m     23\u001b[0m                   time_horizon\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtime_horizon, time_augment\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtime_augment,\n\u001b[1;32m     24\u001b[0m                   nb_units\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnb_units, nb_layers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mnb_layers,\n\u001b[1;32m     25\u001b[0m                   activation\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mactivation, lambda_trs\u001b[38;5;241m=\u001b[39mlambda_trs,\n\u001b[1;32m     26\u001b[0m                   use_time_dep_lambda\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39muse_time_dep_lambda, learning_rate\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[0;32m---> 28\u001b[0m \u001b[43moden\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit(x\u001b[38;5;241m=\u001b[39m[t_train, x_train], y\u001b[38;5;241m=\u001b[39my_train, epochs\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_train), verbose\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m     29\u001b[0m oden\u001b[38;5;241m.\u001b[39mfunc\u001b[38;5;241m.\u001b[39msave_weights(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, split_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight.h5\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     31\u001b[0m ts, xs \u001b[38;5;241m=\u001b[39m get_dataset(nb_samples\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtest_nb_sample, nb_timestep\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtest_nb_timestep,\n\u001b[1;32m     32\u001b[0m                      t_span\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtest_t_span, seed\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtest_seed, noise_level\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mtest_noise_level,\n\u001b[1;32m     33\u001b[0m                      params\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mosc_params)\n",
      "Cell \u001b[0;32mIn[2], line 100\u001b[0m, in \u001b[0;36mODENetwork.solver\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m x0 \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim),))\n\u001b[1;32m     99\u001b[0m x \u001b[38;5;241m=\u001b[39m x0\n\u001b[0;32m--> 100\u001b[0m xr \u001b[38;5;241m=\u001b[39m \u001b[43mLambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreversing_operator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marguments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdim\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwith_batch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m ls_x, ls_xr \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT):\n",
      "File \u001b[0;32m~/ptvenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/ptvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 2), dtype=float32, sparse=None, name=keras_tensor_7>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "run(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662eff15-a43d-4c35-8e76-25e1136dfc01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
